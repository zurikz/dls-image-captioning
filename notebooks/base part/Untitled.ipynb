{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "false-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/coco/data/'\n",
    "img_codes_path = DATA_PATH + 'image_codes.npy'\n",
    "captions_path = DATA_PATH + 'captions_tokenized.json'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "determined-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import CaptionDataset, Vocab\n",
    "from utils import pad_collate_fn\n",
    "from model import CaptionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "apparent-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(captions_path)\n",
    "train = CaptionDataset('train', vocab, img_codes_path, captions_path)\n",
    "val = CaptionDataset('val', vocab, img_codes_path, captions_path)\n",
    "test = CaptionDataset('test', vocab, img_codes_path, captions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "\n",
    "train_loader = DataLoader(train, batch_size, num_workers=4, collate_fn=pad_collate_fn)\n",
    "val_loader = DataLoader(val, batch_size, num_workers=4, collate_fn=pad_collate_fn)\n",
    "test_loader = DataLoader(test, batch_size, num_workers=4, collate_fn=pad_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "hidden_size = 512\n",
    "embedding_dim = 512\n",
    "num_layers = 2\n",
    "lstm_dropout = 0.3\n",
    "fc_dropout = 0.5\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "###################\n",
    "\n",
    "model = CaptionNet(\n",
    "    vocab=vocab,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    lstm_dropout=lstm_dropout,\n",
    "    fc_dropout=fc_dropout,\n",
    "    embedding_dim=embedding_dim\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-captioning",
   "language": "python",
   "name": "image-captioning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
